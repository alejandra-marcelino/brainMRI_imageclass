{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530ed20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input, Dropout, Rescaling\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d82aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.path.dirname(os.path.abspath('brain_MRI_classification.ipynb'))\n",
    "datasets_combined = os.path.join(notebook_path, 'brainMRI_data')\n",
    "\n",
    "train_directory = os.path.join(datasets_combined, 'Training')\n",
    "test_directory = os.path.join(datasets_combined, 'Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06832d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 files belonging to 4 classes.\n",
      "Using 2296 files for training.\n",
      "Found 2870 files belonging to 4 classes.\n",
      "Using 574 files for validation.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_dataset = image_dataset_from_directory(train_directory,\n",
    "                                             batch_size = BATCH_SIZE,\n",
    "                                             image_size = IMG_SIZE,\n",
    "                                             shuffle = True,\n",
    "                                             validation_split = 0.2,\n",
    "                                             subset = 'training',\n",
    "                                             seed = 42,\n",
    "                                             label_mode='categorical')\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(train_directory,\n",
    "                                                  batch_size = BATCH_SIZE,\n",
    "                                                  image_size = IMG_SIZE,\n",
    "                                                  shuffle = True,\n",
    "                                                  validation_split = 0.2,\n",
    "                                                  subset = 'validation',\n",
    "                                                  seed = 42,\n",
    "                                                  label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38222ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = image_dataset_from_directory(test_directory,\n",
    "                                            shuffle = False,\n",
    "                                            image_size = IMG_SIZE,\n",
    "                                            label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31deb80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b74285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (224, 224) -> (224, 224, 3) for the 3 color channels\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "# load network without the top classification layers\n",
    "base_model = VGG19(include_top = False,\n",
    "                   weights = 'imagenet',\n",
    "                   input_shape=IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e761ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d5bc576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only augment training set\n",
    "train_augmented = train_dataset.map(lambda x, y: (data_augmentation(x, training = False), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "911a93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.vgg19.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55141435",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Flatten the output layer to 1D\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Add a fully connected layer with 4096 hidden units, ReLU activation\n",
    "x = Dense(4096, activation = 'relu')(x)\n",
    "\n",
    "# Add a dropout layer with 0.2 (20%) rate\n",
    "x = Dropout(0.2)(x) \n",
    "\n",
    "# Add another FC layer, 4096 units, ReLU activation\n",
    "x = Dense(4096, activation = 'relu')(x)\n",
    "\n",
    "# Add another dropout layer with 0.2 (20%) rate\n",
    "x = Dropout(0.2)(x) \n",
    "\n",
    "# Add a final FC layer for classification with 4 units using softmax activation function\n",
    "outputs = Dense(4, activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "837ebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and compile the model\n",
    "model_new = Model(inputs, outputs)\n",
    "model_new.compile(loss='categorical_crossentropy',\n",
    "               optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91102e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 626s 18s/step - loss: 6.4833 - accuracy: 0.6677 - val_loss: 1.0843 - val_accuracy: 0.8171\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 770s 21s/step - loss: 0.4259 - accuracy: 0.9225 - val_loss: 0.3853 - val_accuracy: 0.9111\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 785s 22s/step - loss: 0.0784 - accuracy: 0.9734 - val_loss: 0.3642 - val_accuracy: 0.9129\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 791s 22s/step - loss: 0.0501 - accuracy: 0.9865 - val_loss: 0.4678 - val_accuracy: 0.9164\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 793s 22s/step - loss: 0.0475 - accuracy: 0.9887 - val_loss: 0.4543 - val_accuracy: 0.9286\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 797s 22s/step - loss: 0.0648 - accuracy: 0.9882 - val_loss: 0.3794 - val_accuracy: 0.9338\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 798s 22s/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.3945 - val_accuracy: 0.9024\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 809s 23s/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.3420 - val_accuracy: 0.9425\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 754s 21s/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.3627 - val_accuracy: 0.9286\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 704s 20s/step - loss: 0.0820 - accuracy: 0.9874 - val_loss: 0.6315 - val_accuracy: 0.9024\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 733s 20s/step - loss: 0.0644 - accuracy: 0.9826 - val_loss: 0.6488 - val_accuracy: 0.9024\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 718s 20s/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 0.7092 - val_accuracy: 0.8937\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 716s 20s/step - loss: 0.1123 - accuracy: 0.9791 - val_loss: 0.5818 - val_accuracy: 0.9286\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 718s 20s/step - loss: 0.1309 - accuracy: 0.9778 - val_loss: 0.6039 - val_accuracy: 0.9303\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 714s 20s/step - loss: 0.1109 - accuracy: 0.9804 - val_loss: 1.1096 - val_accuracy: 0.9007\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 736s 21s/step - loss: 0.0510 - accuracy: 0.9861 - val_loss: 0.8615 - val_accuracy: 0.9077\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 737s 21s/step - loss: 0.1021 - accuracy: 0.9869 - val_loss: 1.0312 - val_accuracy: 0.9042\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 738s 21s/step - loss: 0.1314 - accuracy: 0.9808 - val_loss: 1.4162 - val_accuracy: 0.8902\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 741s 21s/step - loss: 0.2849 - accuracy: 0.9639 - val_loss: 1.2495 - val_accuracy: 0.9024\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 727s 20s/step - loss: 0.0880 - accuracy: 0.9874 - val_loss: 1.0730 - val_accuracy: 0.8990\n"
     ]
    }
   ],
   "source": [
    "results_new = model_new.fit(train_augmented, epochs = 20, validation_data = validation_dataset, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a9d9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Flatten the output layer to 1D\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Add a fully connected layer with 4096 hidden units, ReLU activation\n",
    "x = Dense(4096, activation = 'relu')(x)\n",
    "\n",
    "# Add a dropout layer with 0.2 (20%) rate\n",
    "x = Dropout(0.5)(x) \n",
    "\n",
    "# Add another FC layer, 4096 units, ReLU activation\n",
    "x = Dense(4096, activation = 'relu')(x)\n",
    "\n",
    "# Add another dropout layer with 0.2 (20%) rate\n",
    "x = Dropout(0.5)(x) \n",
    "\n",
    "# Add a final FC layer for classification with 4 units using softmax activation function\n",
    "outputs = Dense(4, activation = 'softmax')(x)\n",
    "\n",
    "# Configure and compile the model\n",
    "model_new2 = Model(inputs, outputs)\n",
    "model_new2.compile(loss='categorical_crossentropy',\n",
    "               optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab23feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 366s 10s/step - loss: 2.5798 - accuracy: 0.8005 - val_loss: 1.1642 - val_accuracy: 0.8659\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 389s 11s/step - loss: 1.3467 - accuracy: 0.8754 - val_loss: 1.1656 - val_accuracy: 0.8780\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 426s 12s/step - loss: 1.2034 - accuracy: 0.8981 - val_loss: 2.1256 - val_accuracy: 0.8728\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 449s 13s/step - loss: 0.7628 - accuracy: 0.9216 - val_loss: 0.8045 - val_accuracy: 0.9111\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 459s 13s/step - loss: 0.6814 - accuracy: 0.9368 - val_loss: 2.4354 - val_accuracy: 0.8118\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 471s 13s/step - loss: 0.5718 - accuracy: 0.9395 - val_loss: 2.2370 - val_accuracy: 0.8711\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 460s 13s/step - loss: 0.4314 - accuracy: 0.9578 - val_loss: 0.6484 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 444s 12s/step - loss: 0.2590 - accuracy: 0.9721 - val_loss: 1.1013 - val_accuracy: 0.9059\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 432s 12s/step - loss: 0.2793 - accuracy: 0.9678 - val_loss: 0.7986 - val_accuracy: 0.9355\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 461s 13s/step - loss: 0.2520 - accuracy: 0.9752 - val_loss: 1.7170 - val_accuracy: 0.9059\n"
     ]
    }
   ],
   "source": [
    "results_new2 = model_new2.fit(train_augmented, epochs = 10, validation_data = validation_dataset, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504e2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
